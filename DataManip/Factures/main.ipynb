{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### À faire\n",
    "+ vitesse dans ajustement des dates\n",
    "+ flattenList, pairing : transformer en fichiers, ou pickles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Motivation du projet\n",
    "Une entreprise s'est faite voler des sommes considérables pendant quelques années entre 2005-2021, dates pour lesquelles nous disposons de toutes les transactions regroupant notamment les informations Montant, date, quart de travail, numero de facture. \n",
    "\n",
    "C'est une petite entreprise avec peu de personnel. Le voleur avait un horaire regulier et etait la depuis quelques temps et a vole avec regularite et progressivement. Le voleur s'est fait demasque progressivement: le responsable de contabilite s'est apercu que l'entreprise achetait plus d'un type de produit que l'entreprise n'en vendait: ces produits disparaissaient. Sur le coup, le responsable a attribue le phenomene au systeme de gestion des commandes, entre autre, sans faire davantage d'exploration; le responsable a ete negligeant. Il a fallu, bien plus tard, et avec la mefiance subconsciente du responsable qu'un client inoportunement ramene un produit qui avait ete faussement vendu. Alors une longue recherche pour decouvrir des preuves et identifier le voleur a debute. L'appel en justice etait trop complique pour etre interessant au proprietaire de l'entreprise, notamment parce que l'importance du vol exigeait une poursuite au criminel ou le fardeau de la preuve exigeait des temoins, ce qui aurait ete nefaste a l'entreprise. \n",
    "\n",
    "J'explique le systeme du voleur. Les produits etaient voles simplement en n'entrant pas leur vente dans le systeme. Le voleur employait peut-etre un moyen supplementaire pour faire mieux passer la disparition du produit de l'inventaire. Le voleur participait aussi au processus de commande. Pour sortir un maximum de monnaie de la caisse, le voleur faisait passer des montants payes par carte sur des factures de services payees en espece. Ainsi, on retrouvait des factures de service payees sur deux cartes differentes et en espece. Ainsi, la comptabilite balancait et le voleur n'etait pas dependant a la forme de payment du client qui achetait le produit vole. \n",
    "\n",
    "J'aimerais parle d'une deuxieme entreprise, dont j'ai moins besoin de conserver l'anonimat : un cafe etudiant OSBL. En fait, plus generalement, des cafes etudiants de l'universite de Montreal. Plusieurs ont des comtabilites anemiques. Un des mieux organise fonctionne avec 70 benevoles. Il y a un suivit des commandes et des transactions par carte. Ceux en espece dependent de ce que les benevoles indiquent sur la caisse. Le fait que les benevoles travaillent en paire, que la caisse soit exposee a la vue des clients et qu'un petit ecran indique les montants entres dans la caisse donnent une bonne assurance au systeme. Cependant, ce n'etait pas le cas de la plupart des cafes de l'universite. Aussi, en dehors de la surveillance circonstentielle constante et systemique, peut etre le tier de la valeur des produits vendus n'est pas serieusement comptabilisé: il n'y a pas de suivit quand a la vente desdits produits, mais seulement de leur commande. Le voleur a là une bonne marge de manoeuvre \"a couvert\": sauf constat que le montant des ventes en espece les jours de travail de ce benevole sont anormalement bas, le vol ne soulevera pas de mefiance. \n",
    "\n",
    "J'ai eu l'idee de faire un systeme de détection de fraude par un modele semblable a une serie chronologique se basant principalement sur les montants, le temps et les quarts de travail associes aux transactions en espece. L'interet d'un tel systeme est qu'il se base principalement sur des donnees generalement disponibles lors de paiements. L'argent physique ne peut être volé qu'à la base de la chaine (lors de l'achat du produit) car par la suite, a chaque transfert, l'argent est compte; de plus les intermediaires sont generalement nombreux: le client, le caissier, le compteur de la caisse, le teneur de livre, celui qui depose l'argent a la banque, la banque. La base de la tenue de livre sont le montant des depenses et le montant quotidien des revenus. L'historique des depenses et des revenus peut etre trouve generalement a la banque et au travers des sous-traitants. Les revenus attendus des produits sont accessibles si leurs prix de vente sont fixes et que les pertes sont compilées. \n",
    "\n",
    "Plus generalement, les moyens de surveillance sont souvent specifiques: le suivit du passage de chaque produit dans l'entreprise, notamment sa vente et sa commande. L'ennui d'un tel systeme est que si les voleurs ont suffisement de moyens et qu'ils connaissent suffisement le système, le vol peut passer indétecté. Le système ici développé repose sur la prévision des revenus en espèce d'une entreprise pour détecter une variation anormale. Ce système ne peut être trompé par un truc: les montants volés doivent être augmentés progressivement pour apparaitre comme une tendance générale normale dans les ventes de l'entreprise. Il est attendu que l'explication pour la variation anormale doit ensuite être recherchée. Nous proposerons certains tests de corrélations, entre autre avec les quarts de travail, visant à identifier du vol à la tire.\n",
    "\n",
    "J'espère que le système puisse s'avérer intéressant pour les entreprises suivantes. Celles avec beaucoup de produits dont le suivi n'est pas fait spécifiquement pour chaque produit. Celles dont les employés changent souvent. Celles dont la comptabilité est minimale. Celles qui sont à risque de machinations élaborées. Celles ne pouvant isoler les profits associés aux produits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "###################\n",
    "\n",
    "\n",
    "\n",
    "Nous disposons de données de qualité: exhaustives, d'une source commune, avec plusieurs attributs suplémentaires à ceux exigés. Elles correspondent toutes à des montants en espèce. Le test consiste en ce que le modèle permette d'identifier les années de fraude entre 2005 et 2021. Il est attendu que plusieurs abhérations détectées par le modèle soient attribuables à autre chose que de la fraude. La fonction du modèle est de donner un signal d'alarme: on peut se permettre quelques fausses alarmes, surtout si le système s'adresse à de petites entreprises pouvant souvent expliquer autrement un soudain changement dans les montants (e.g. incitatifs à payer par carte).\n",
    "\n",
    "Nous pensons à un modèle de série chronologique avec quelques paramètres supplémentaires. Nous faisons l'hypothèse qu'une bonne partie des changements est stochastique, ce qui décourage l'utilisation d'un modèle de régression multivariée, bien que ce dernier soit intéressant pour son interprétabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage\n",
    "Dans les colonnes de validation des donnees, les codes indiquent le critère de validation employé sur les données groupées d'après le nom de la colonne de validation. Voici la signification approximative des codes, \n",
    "+ sum0: Les données groupées sommes à 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions pour l'entreprise\n",
    "\n",
    "En quoi consistes les factures avec plusieures dates?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexions et leçons a retenir\n",
    "+ Y a-t-il un modele que j'aurais pu appliquer aux donnees sans traiter le fait que certaines donnees consecutives etaient liees, d'autres non?\n",
    "+ À quel point peut-on travailler les donnees avant d'en faire une analyse formelle (e.g. modèles, tests d'hypothèses)? Autrement dit, quel est la limitte de faire des manipulations/traitement a l'oeuil et avec hypotheses # d'avantage que le 'cleaning' de données standart ?\n",
    "+ Je ne sais pas et je ne trouve pas de ressources pour travailler des df dont les valeurs sont des objets liste.\n",
    "+ Dans les listes, les valeurs redondantes posent problème; l'indice est moins fort que dans des arrays\n",
    "+ Quel est le bon usage des lists comprehension?\n",
    "    + creer des listes\n",
    "    \n",
    "+ Prq est-ce que flattenList supprime test si flattenList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "+ L'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des données\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "path='/Users/charlottebacave/Documents/travail/StartUp/CVD/cmptants/principal'\n",
    "os.getcwd()#Sortie: '/Users/charlottebacave/Documents/travail/prog'\n",
    "#dataX='20052021.1.xls'\n",
    "#dfOrigin=pd.read_excel(dataX,sheet_name='20052021Clean.csv')\n",
    "dataX='anonyme'\n",
    "dfOrigin=pd.read_csv(dataX)\n",
    "df=dfOrigin.copy()\n",
    "#joli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Correction du nom des attributs\n",
    "Zchap=dfOrigin.columns[1][-2]#é est devenu un Z étrange\n",
    "t=[re.sub(pattern=Zchap,repl='e',string=c) for c in dfOrigin.columns]#'e' a la place de 'é' pour eviter de future diffiucltees\n",
    "#on enleve les '.' en fin de mots pour permettre l'appel des colonnes df.col\n",
    "t=[re.sub(pattern='([\\w\\s]*)\\.$', repl='\\g<1>', string=s ) for s in t]\n",
    "#strip s'est avere necessaire\n",
    "ok=[re.sub(pattern=' ', repl='', string=s) for s in t[2:7]]\n",
    "t=('Dencaiss '+'Dentree '+' '.join(ok)+' '+'Mapplique').split(' ')\n",
    "df.columns=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Iabandon=[]#nous regroupons sous cette liste tous les index dont le nettoyage est problematique pour les traites separements a la fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du format des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A l'observation, nous pensons que l'ordre des donnes a l'importation a une signification. Nous en faisons donc un attribut.\n",
    "dfC['IndexRef']=dfC.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test=df.Dencaiss.str.replace(pat=Zchap,repl='é',regex=True)\n",
    "#test[test.isna().eq(False)].sample(20)#on remarque que le mois d'aout contient  z^ en minuscule a place de u\n",
    "\n",
    "pattern=\"(\" + Zchap + \")|(\"+Zchap.lower()+')'\n",
    "def remplace(matchobj):\n",
    "    if matchobj.group(1): return 'e'\n",
    "    elif matchobj.group(2): return 'u'\n",
    "mask=df.Dencaiss.str.replace(pat=pattern,repl=remplace,regex=True)\n",
    "t=df.Dencaiss.where(mask.isna(),mask)#mask\n",
    "\n",
    "#tchec up\n",
    "re.findall(Zchap.lower(),str(t.values))#vide\n",
    "re.findall(Zchap.lower(),str(df.Dencaiss.values))#vide\n",
    "print(df.Dencaiss.isna().sum()-t.isna().sum())#0\n",
    "#tchec up reussi\n",
    "df.Dencaiss=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Apres quelques observations, on decides de faire les corrections suivantes; \n",
    "#si erreur il y a dans la correction en dehors d'etre incomplete, nous comptons la reperer ulterieurement lors de l'observations des donnees abherrantes\n",
    "\n",
    "#A ameliorer la vitesse\n",
    "\n",
    "\n",
    "#Pour tout df, caracteres indésirables\n",
    "t=')|('.join([Zchap,#1\n",
    "              Zchap.lower(),#2\n",
    "              ' \\$',#3\n",
    "              '0',#4\n",
    "             '1Ê','2Ê','3Ê',#5 to 7\n",
    "             ','])#8\n",
    "pattern='('+t+')'\n",
    "\n",
    "def funRepl(matchobj):\n",
    "    if matchobj.group(1): return 'e'\n",
    "    elif matchobj.group(2): return 'u'\n",
    "    elif matchobj.group(3): return ''\n",
    "    elif matchobj.group(4): return '0'\n",
    "    elif matchobj.group(5) or matchobj.group(6) or matchobj.group(7): return ''\n",
    "    elif matchobj.group(8):return '.'\n",
    "def aApplique(serie,pattern,funRepl):\n",
    "    mask=serie.str.replace(pat=pattern,repl=funRepl,regex=True)\n",
    "    t=serie.where(mask.isna(),mask)\n",
    "    return t\n",
    "\n",
    "dfC=df.apply(lambda serie: aApplique(serie,pattern,funRepl),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#On est convaincu que la donnee a ete transformee lorsqu'on a tente d'appliquer pd.to_Datetime\n",
    "#Faire bien atention lors de l'utilisation de cette fonction pour ne pas perdre les donnees d'origine.\n",
    "\n",
    "\n",
    "#pd.DatetimeIndex(df.Dencaiss[0:1000])#erreur par juil.\n",
    "test[180:200]#Donc 2005-06-30 00:00:00 est lisible, 182 pas lisible\n",
    "pd.DatetimeIndex(pd.Series('30-jul-2005'))#c en anglais:jul, le plus simple demeure les chiffres\n",
    "#extraire la representation actuelle des mois dans Dencaiss, puis corriger\n",
    "t=dfC.Dencaiss.str.findall(pat=r'(?<=-)[a-zA-Z]*')\n",
    "t.sample(20)#les mois sont ecris sept,oct,nov,dec, fevr, avr, juil,aout : pas de mois de mars,juin,,mai apparement\n",
    "#t=dfC.Dencaiss.str.findall(pat=r'((?:-)[a-zA-Z0-9]*(?:-))')\n",
    "month_dict = {'jan.':'01', 'fevr.':'02', 'mar.':'03', 'avr.':'04', 'mai.':'05', 'jun.':'06', 'juil.':'07', \"aout\":'08', 'sept.':'09', 'oct.':'10', 'nov.':'11', 'dec.':'12'}\n",
    "test=dfC.Dencaiss.dropna().replace(month_dict,regex=True)\n",
    "k=test[pd.to_datetime(test,errors='coerce').isna()].keys()\n",
    "test.loc[k]#01-0805; un'- a disparu en plus du debut de l'annee\n",
    "test.loc[k].unique()#le probleme est systematique et contingeante aux mois 08:aout\n",
    "#set(dfC.Dencaiss.unique())#On trouve que le mois d'aout etait entre malhabillement 'aout.' dnas month-dict\n",
    "#apres modification, test fonctionne\n",
    "test=pd.to_datetime(test)\n",
    "dfC.Dentree.replace(month_dict,regex=True,inplace=True)\n",
    "dfC.Dencaiss.replace(month_dict,regex=True, inplace=True)\n",
    "\n",
    "test=pd.to_datetime(dfC.Dencaiss)\n",
    "dfC.Dencaiss=test\n",
    "test=pd.to_datetime(dfC.Dentree)\n",
    "dfC.Dentree=test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['Facture']=[str(e) for e in df['Facture']]\n",
    "1#df[['Client','Facture']].applymap(lambda e: re.sub(string=e, pattern=t, repl=funRepl))\n",
    "df['Facture']=pd.to_numeric(df.Facture,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test=pd.to_numeric(dfC.Montant)\n",
    "dfC.Montant=test\n",
    "test=pd.to_numeric(dfC.Mapplique)\n",
    "dfC.Mapplique=test\n",
    "\n",
    "x=dfC.Arrond.where(dfC.Arrond.isna().eq(False),0)\n",
    "dfC.Arrond=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#L'arithmetique numerique n'est pas magique: suite a des operations, les egalites sont perdues. Il faut mettre les donnees numeriques\n",
    "#en nombres naturels, afin d'eliminer les erreurs de representation en virgules flottantes.\n",
    "\n",
    "num=['Montant','Arrond','Mapplique']\n",
    "\n",
    "def arrond(x,p):\n",
    "    #arrondi x a p apres la virgule\n",
    "    if np.isnan(x):\n",
    "        return x\n",
    "    s=1\n",
    "    if x<0:\n",
    "        s=-1\n",
    "    x=np.abs(x)\n",
    "    \n",
    "    x=x*(10**p)\n",
    "    r=x%1\n",
    "    x=int(x)#x>=int(x) pour tout x>0\n",
    "    if r>=.5:\n",
    "        x=x+1\n",
    "    x=x*(10**-p)\n",
    "    return(x*s)\n",
    "\n",
    "dfC[num]=(dfC[num]*100).applymap(lambda x: arrond(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRef=dfC.copy()\n",
    "# a comparison base for dfC all along the section; takes the latest value of dfC before we make a change to dfC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations instinctives sur les données\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAN\n",
    "\n",
    "Pour commencer, on se penche sur les attributs quantitatifs(Montant et Mappliquee). On utilise Facture comme facteur de concordance entre ces deux attributs.\n",
    "\n",
    "# Observations\n",
    "+ Mapplique + Arrond : Montant\n",
    "+ les Arrondis ont une tendance a la hausse. Leur moyenne(.0009) a une difference avec la moyenne attendue (0) plus de six fois l'equart type empirique (.00015=.02/sqrt(6400)).\n",
    "+ there has been no changes on the expression of the information after rounding: we can assume the representation at data importation was correct. Rounding up was useless.\n",
    "+ For the sake of experience, we pursue using numbers with numerical representation errors. This kind of quantitative data is not used most of the time for exact equalities; maybe we will need to change it to an integer type so as to use it like a categorical variable. We would then learn this representation is needed for any accounting activity.\n",
    "\n",
    "# Conclusion:\n",
    "\n",
    "+ Les Nan correspondent entre Dencaiss,Dentree,Montant,Client et Quart: et alors Facture  et Mappliquee ne sont pas Nan\n",
    "+ Mapplique.isna == Facture.isna\n",
    "+ Arrond==Nan est interprete Arrond==0; l'arrondis ne semble pas appliquee de maniere systemique: beaucoup de Montant ou Mapplique qui ne sont pas (x Mod .05 == 0)\n",
    "+ Il est necessaire d'observer les 0 et nombres négatifs pour mieux expliquer les données\n",
    "+ Il n'y a que 4% des données qui sont problématiques; elles sont cependant d'intérêt car elles peuvent justement révéler de la fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#premiere observations\n",
    "\n",
    "#NaN\n",
    "dfC[dfC.Montant.isna()].isna().sum(axis=0)\n",
    "#Dencaiss=Dentree=Montant=Client=Quart= 890_Nan:\n",
    "#Arrond=18966, Il y a beaucoup d'absences d'arrondis (arrondis=0)\n",
    "#Facture=Mapplique=42 ??\n",
    "subs=dfC[['Montant','Mapplique']].mod(.01)# on voit les erreurs de precision dans chiffres significatifs\n",
    "subs=subs.where(subs.eq(.01),0)\n",
    "subs.eq(0).sum(axis=0)-len(subs)#a l'analyse, on ne voit plus les erreurs: \n",
    "# fct where a une tolerance sur le match recherche\n",
    "\n",
    "#trouver regle Arrondis: comment ils sont determines\n",
    "md=dfC[['Montant','Mapplique']].mod(.05)\n",
    "t=md.lt(1e-4)|md.eq(.05)\n",
    "#md[t.sum(axis=1).eq(1)] # 'dfC m0d .05' s'est bel et bien appliqué a chaque entree de md\n",
    "dfC[dfC.Arrond.ne(0)]# Montant-Arrond==Mapplique, en general\n",
    "1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Données quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pour simplifier\n",
    "num=['Montant','Arrond','Mapplique']\n",
    "dfT=dfC[num]\n",
    "dfT=dfT.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyse Montant-Arrond!=Mapplique; sans NaN\n",
    "err=dfT[(dfT.Montant-dfT.Arrond)!=dfT.Mapplique]\n",
    "#plus de 90% des cas Montant-Arrond!=Mapplique sont dus aux nombres significatifs :\n",
    "t1=err[num]%.01\n",
    "t2=t1.ne(.01)&t1.ne(0)\n",
    "1-t2.mean()#<.01\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Nan:Facture == #Nan:Mapplique = 42 ??\n",
    "test=dfC[dfC.Facture.isna()]\n",
    "test.shape[0]==test.Mapplique.isna().sum()#Facture.isna() == Mapplique.isna()\n",
    "#test\n",
    "#Dans les cas ou Facture et/ou Mapplique sont NaN, on remarque que le client est souvent un employé de l'entreprise.\n",
    "#Aussi, à un montant positif correspond le même montant negatif a la meme date: probablement des transactions particulieres, annulees, etc\n",
    "#Cependant, ce n'est pas toujours le cas.\n",
    "#Esperons que l'analyse des nombres negatifs eclairera la situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14606741573033707"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mappliquee vs Montant\n",
    "dfg=pd.DataFrame([dfC.Mapplique,dfC.Montant]).transpose()\n",
    "#Dans les cas où Nan presents:\n",
    "dfg[dfg.Mapplique.isna()].Montant.isna().sum()# 0:Mapplique.isna() => (Montant!=Nan)\n",
    "dfg[dfg.Montant.isna()].Mapplique.isna().sum()# 0:Montant.isna() => (Mapplique!=Nan)\n",
    "#Dans les cas sans Nan:\n",
    "#dfg.dropna().Montant.sub(dfg.dropna().Mapplique)#dfg.dropna().Mapplique*-1\n",
    "#Etrangement, il y a des problemes: preuve que pd.to_numeric peut etre utile\n",
    "etrange=(dfg.dropna().Montant-dfg.dropna().Mapplique).abs().gt(3)#-dfC.loc[dfg.dropna().index].Arrond).abs().gt(10^-1)\n",
    "etrange.sum()# 623:il y a peu de cas où Arrond n'explique pas la difference Mapplique,Montant\n",
    "\n",
    "Ietrange=etrange[etrange].index\n",
    "test=dfC.loc[Ietrange]\n",
    "test[['Montant','Mapplique']].sample(30)#On remarque beaucoup Montant==0\n",
    "test[test.Montant.eq(0)].Mapplique.lt(0).mean()#Dans les cas Montant==0, ya 15% de Mappliquee negatifs\n",
    "#Mieux vaut attaquer le probleme des negatifs et nuls avant d'aller plus de l'avant avec Montant vs Mapplique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5051652077911837"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#est-ce que les Mapplique sont systématiquement arrondis? C a dire payable sans pièces de 1ç\n",
    "t=dfC.Montant.mod(5).eq(0)\n",
    "t.mean()#.5: la moitié necessitent des 1ç, mais on sait que certaines entrees doivent être agglutinées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.06586309e-06, -2.17006770e-06, -2.55559789e-06,\n",
       "        -2.42124646e-06],\n",
       "       [-2.17006770e-06,  7.01371080e-06, -2.52837448e-06,\n",
       "        -2.39545422e-06],\n",
       "       [-2.55559789e-06, -2.52837448e-06,  7.81056732e-06,\n",
       "        -2.82102617e-06],\n",
       "       [-2.42124646e-06, -2.39545422e-06, -2.82102617e-06,\n",
       "         7.54826002e-06]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Speculation: la hausse des prix par arrondis peut montrer que \n",
    "#les produits prennent la forme sous le montant qui sera obtenu apres arrondis (e.g. 3.99$)\n",
    "#Sinon, hypothèse H1,\n",
    "#Les .005$ sont arrondis a la hausse et surviennent lors du calcul des taxes pour certaines factures: \n",
    "#         soit que par hasard il y a une facture recurrentte particuliere dont le calcul de taxe genere XX.XX5$ exactement\n",
    "#         Ou encore, au niveau du calcul numérique, l'ordinateur arrondis a 1/2*10^-3 pres la valeur lors du calcul des taxes, puis applique la procedure d'arrondis\n",
    "\n",
    "dfC.Arrond.mean()#.023\n",
    "\n",
    "#on enleve les cas ou arrond==0 afin d'enlever l'influence des factures avec multiples lignes.\n",
    "#Cela augmente la variance et rend plus plausible des valeurs extremes: si le test est positif, il le serait\n",
    "# aussi en prenant en compte les valeurs 0\n",
    "t=dfC.Arrond[dfC.Arrond.ne(0)]\n",
    "t1=t[:int(len(t)/2)].mean()#.12\n",
    "t2=t[int(len(t)/2):].mean()#.06\n",
    "(t1-t2)/((t1+t2)/2)#.68, une statistique intuitive\n",
    "\n",
    "#faisons un peu de statistiques\n",
    "n=int(len(t)/2)\n",
    "#n*t1 suit une loi multinomiale (n,(p1,p2,p3,p4,p5),(-2,-1,0,1,2)),\n",
    "#estimateur par la méthode de vraissemblance-max de pI est la moyenne nI/n\n",
    "v=np.array([-2,-1,1,2])\n",
    "p=np.array([dfC.Arrond.eq(vk).mean() for vk in v])\n",
    "n=len(dfC)\n",
    "#esperance\n",
    "\n",
    "#np.T(p)\n",
    "p=np.repeat(p,len(p)).reshape(len(p),len(p))\n",
    "MCov=p.dot(p.T)\n",
    "(1/len(t)*(np.diag(p.T[0])-MCov))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sous l'hypothèse H : groupe 1 est similaire a groupe 2, t1 suit meme loi que t2 et p peut être évalué:\n",
    "#H => p~=(t1+t2)/2= .090\n",
    "# H => on peut estimer t1-t2 suivant une loi normale N(0,p(1-p)/n)\n",
    "S=t1-t2#.0613\n",
    "p=t.mean()#.09\n",
    "T=np.sqrt(n/(p*(1-p)))*S# T~N(0,1)\n",
    "#T=12: bcp trop extrème pour que H soit crédible : t1 différent de t2\n",
    "#nous faisons la conclusion que les arrondis ont un comportement différent entre \n",
    "#la moitiée des données venant a une date ultérieure à la deuxième moitié.\n",
    "year=dfC.Dencaiss.dt.year.dropna()\n",
    "sol=0\n",
    "for i in range(int(year.min()),int(year.max())+1):\n",
    "    a=dfC.Montant.loc[year[year.le(i)].index]\n",
    "    b=dfC.Montant.loc[year[year.gt(i)].index]\n",
    "    test=abs(a.mean()-b.mean())\n",
    "    #if (sol<)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régulariation de Montant\n",
    "La valeur d'intérêt est le Montant. Cette section du projet est comparable à de la comptabilité. Nous cherchons à organiser les Montants pour qu'ils s'expliquent par les autres attributs. Nous traitons les valeurs comme discrètes: la seule question au final est MontantPrédit == Montant; pas d'imprécisions tolérées. Nous fairons usages des différents attributs de chaque Montant comme suit:\n",
    "\n",
    "01. Si les lignes des données ne sont pas disctinctes, nous mettrons l'index de depart comme attribut.\n",
    "02. fMontant(Nan): Montant==Nan\n",
    "03. fMapplique(Nan):  Mapplique==Nan\n",
    "1. fArrond('Arrond'): Montant==Mapplique+Arrond\n",
    "2. fFacture('Facture'): a=dfC.groupby('Facture').agg(sum)\n",
    "        True: fArrond(a)\n",
    "        0: fMontant(0) or fMapplique(0)\n",
    "3. fFacture('Client')\n",
    "\n",
    "A chaque test, on note le resultat à chaque ligne: \n",
    "    'zero' pour un zéro qui semble signifier un balancement, \n",
    "    1 pour un cas où fArrond réussi,\n",
    "    0 dans le cas contraire.\n",
    "On n'applique les tests qu'aux cas non-positifs des tests précédents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on corrige les doublons\n",
    "\n",
    "dfC['Jour']=dfC.Dencaiss.dt.day\n",
    "dfC['Mois']=dfC.Dencaiss.dt.month\n",
    "dfC['Annee']=dfC.Dencaiss.dt.year\n",
    "\n",
    "sub=['Montant', 'Arrond', 'Client', 'Quart',\n",
    "       'Facture', 'Mapplique','Jour','Mois','Annee']\n",
    "test=dfC[dfC[sub].duplicated()]\n",
    "test.shape#28\n",
    "test.sort_values('Montant')\n",
    "#etrangement, duplicated() ne semble pas fonctionner comme attendu: certaines valeurs ne se retrouvent qu'une seule foix\n",
    "idx = np.unique(np.sort(dfC[sub], 1), axis=0, return_index=True)[1]\n",
    "dfC.value_counts().gt(1).sum()+1 == len(dfC)-len(idx) #True\n",
    "errors=[e for e in range(len(dfC)) if e not in idx]\n",
    "test2=dfC.loc[errors].sort_values('Montant')\n",
    "test2.shape[0]#20\n",
    "test2.merge(test, how='inner',right_index=True,left_index=True).shape[0] == test2.shape[0]#True\n",
    "#On note tres peu de doublons; en observant tous les elements des deux methodes, soit tous ceux dans test\n",
    "# les doublons sont aux indices 11019, 11020, 11021, 11022, 12850, 12851, 12852\n",
    "# Et ils sont tous suivis d'une ligne aux attributs identiques sauf pour le Montant, qui est de meme valeur mais negative\n",
    "# Nous en deduisons qu'ils sont des erruers d'entree dans la machine: l'employe entrait par erreur un montant\n",
    "# Pour corriger, il rentrait une transaction identique mais negative.\n",
    "# Bref, il n'existe pas de doublons a proprement parler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test de validation\n",
    "#la ligne somme a 0\n",
    "def ligne0(df):\n",
    "    r=(df.Montant-(df.Mapplique+df.Arrond)).eq(0)\n",
    "    r.where(r,inplace=True)\n",
    "    return r#.dropna()\n",
    "dfC['Ligne']=ligne0(dfC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Montant/Mapplique==Nan\n",
    "dfC['ValM']=np.nan\n",
    "#On a deja vu que Montant==Nan <=> tous les autres attributs sont NaN sauf Facture et Mappliquee\n",
    "dfSub=dfC[dfC.Mapplique.isna()]\n",
    "# On remarque beaucoup de cas ou deux lignes successives prennent des valeurs qui sommes a 0.\n",
    "#Nous considererons ces cas valides\n",
    "\n",
    "########          Jusqu'a present, je n'avais pas fait l'hypothese que l'ordre des lignes a une importance.\n",
    "\n",
    "mask=(dfSub.Montant.values[:-1]+dfSub.Montant.values[1:])==0\n",
    "sol=dfSub.iloc[:-1][mask]\n",
    "idx2=pd.Index([i for i in sol.index+1 if i in dfSub.index])\n",
    "sol=sol.index.append(idx2)\n",
    "#dfSub.loc[sol.sort_values()]\n",
    "dfC.loc[sol,'ValM']='consec0'\n",
    "len(sol)#37#\n",
    "\n",
    "dfSub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=pd.Series([[1],[2],[3]])\n",
    "# #pd.Series[[l.append('t') for l in test.values]]\n",
    "# [l.append(['t']) for l in test.values]\n",
    "# test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "                               ...                        \n",
       "25357    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "25358    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "25359    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "25360    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "25361    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "Name: (MontantVal, consecNeutre), Length: 25362, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On doit juste appliquer ligne0 et comparer la ligne0 de diff0 avec celles de diff1, diff2 ...\n",
    "\n",
    "\n",
    "diff1=dfC[num][:-1].add(dfC[num][1:].reset_index())\n",
    "diff1.eq(0).sum()#Montant;Mapplique: 308;464\n",
    "diff2=diff1[num][:-1].add(dfC[num][2:].reset_index())\n",
    "diff2.eq(0).sum()#15;20\n",
    "diff3=diff2[num][:-1].add(dfC[num][3:].reset_index())\n",
    "diff3.eq(0).sum()#15;42\n",
    "diff4=diff1[num][:-1].add(dfC[num][4:].reset_index())\n",
    "diff4.eq(0).sum()#4;2\n",
    "\n",
    "## Je ne sais comment proceder avec un objet liste comme valeurs dans les cellules d'une colonne\n",
    "# https://stackoverflow.com/questions/26806054/how-to-use-lists-as-values-in-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/53742832/is-there-a-way-to-use-lists-as-values-in-a-dataframe\n",
    "dfC['MontantVal','consecNeutre']=[[]]*dfC.shape[0]\n",
    "m=pd.concat([diff1.Montant.eq(0),pd.Series(False)],axis=0,ignore_index=True)\n",
    "for l in dfC.loc[ m ,[['MontantVal','consecNeutre']]].values:\n",
    "    l[0].append(1) \n",
    "dfC['MontantVal','consecNeutre']\n",
    "# Ma boucle n'a pas eu l'effet escompte\n",
    "\n",
    "#Je dois donc multiplier les colonnes: trouver les categories a considerees pour decrire les listes.\n",
    "#pour une somme entre 2 et n elements:\n",
    "# A) Si on considera qu'une donnee fait partie d,un seul ensembles:\n",
    "#  Alors la categorisation serait: x lignes avant (-x) ou apres (x)\n",
    "# B) Sinon\n",
    "#  tous les ensembles possibles\n",
    "\n",
    "# A -> (n-1) colonnes\n",
    "# B -> n*(n+1)/2 - 1 colonnes\n",
    "#Soit avec n=4: A=3 (ou 6 si valeurs Vrai ou Faux) , B=9\n",
    "\n",
    "# Une question plus generale et utile a ce point-ci est si l'objectif est que chaque ligne corresponde a une donnee\n",
    "# C'est une question de modelisation\n",
    "# La reponse est Est-ce que je compte faire des hypothèses pour utiliser mes statistiques pour davantage nettoyer les donnees\n",
    "# Ou \n",
    "# vais-je directement appliquer un modele qui utilise les statistiques comme parametre?\n",
    "\n",
    "# Utiliser les statistiques comme parametres dans un modele est plus lisible. Encore faut-il trouver un modele qui le permette.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arrond       17721\n",
       "Mapplique       20\n",
       "Montant         15\n",
       "index            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=diff1[diff1.Montant.eq(0)]\n",
    "i=sub.index.union(sub.index+1)\n",
    "\n",
    "\n",
    "#test=\n",
    "dfC.loc[i][num][:50]\n",
    "#test[num][:-1].add(test[num][1:])\n",
    "#dfC\n",
    "#sub\n",
    "# sol=dfC.iloc[:-1][mask]\n",
    "# idx2=pd.Index([i for i in sol.index+1 if i in dfSub.index])\n",
    "# sol=sol.index.append(idx2)\n",
    "# #dfSub.loc[sol.sort_values()]\n",
    "# dfC.loc[sol,'ValM']='consec0'\n",
    "diff2.eq(0).sum()#15/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-2e210186ea75>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-2e210186ea75>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    Nous pourrions proceder en faisant une hypothese entre deux donnees\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#groupby un attribut et valider si des totaux sommes a zéro\n",
    "def grVal(df,att):\n",
    "    #ajoute des colonnes tests; ne change aucune donnees: usage securitaire\n",
    "    #on ne fait pas le test sur les cas ou att est sur une seule ligne\n",
    "    gr=dfC.groupby(att). filter(lambda x: x.shape[0]>1). groupby(att)[num].agg(sum)\n",
    "\n",
    "    testCol=att[:4]+'Montant0'\n",
    "    dfC[testCol]=np.nan\n",
    "    i=dfC. where( dfC[att].isin( gr[gr.Montant.eq(0)].index ) ). dropna(axis=0,how='all'). index\n",
    "    dfC.loc[i,testCol]='sum0'\n",
    "    if not (gr[gr.Montant.eq(0)].Mapplique.eq(0).all()):\n",
    "        testCol=att[:4]+'Mapplique0'\n",
    "        dfC[testCol]=np.nan\n",
    "        i=dfC. where( dfC[att].isin( gr[gr.Mapplique.eq(0)].index ) ). dropna(axis=0,how='all'). index\n",
    "        dfC.loc[i,testCol]='sum0'          \n",
    "\n",
    "grVal(dfC,'Facture')     \n",
    "grVal(dfC,'Client')\n",
    "dfC.drop(axis=1,columns=['Jour','Mois','Annee'],inplace=True,errors='ignore')\n",
    "\n",
    "#On remarque beaucoup d'erreurs potentielles dues aux NaN dans Facture et Client.\n",
    "#il semblerait que\n",
    "\n",
    "Nous pourrions proceder en faisant une hypothese entre deux donnees \n",
    "\n",
    "\n",
    "\n",
    "utives qui balancent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.ValM.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Les groupements selon differents attributs ont permis d'expliquer moins de 1/9 des lignes dont la balance n'est pas nulle.\n",
    "testCol=['Ligne','ValM','FactMontant0','ClieMontant0','FactMapplique0','ClieMapplique0']\n",
    "dfTests=dfC[testCol]\n",
    "m=dfTests.isna().all(axis=1)\n",
    "t1=m.mean()#6%\n",
    "t2=1-dfC.Ligne.sum()/dfC.shape[0]#6.72%\n",
    "1-t1/t2#.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On remarque que le probleme est essentiellement lie\n",
    "\n",
    "#dfC[m][['Montant','Mapplique','Arrond','Facture','Client']][:50]\n",
    "i=dfC[dfC.Client.isna()].index#=i+(i-1)\n",
    "i=i.union(i-1)\n",
    "dfC.loc[i][['Montant','Mapplique','Client']][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfTests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-784ec3a010e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#validation tres heuristique selon l'ordre des non-valides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresidus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfTests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresidus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#dfTest['OIdx']=dfTest.index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#dfTest.reset_index(inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfTests' is not defined"
     ]
    }
   ],
   "source": [
    "#validation tres heuristique selon l'ordre des non-valides\n",
    "residus=dfC.loc[dfTests[m].index][num]\n",
    "dfTest=residus.copy()\n",
    "#dfTest['OIdx']=dfTest.index\n",
    "#dfTest.reset_index(inplace=True)\n",
    "\n",
    "#idx=[]#les idx identifies\n",
    "t=dfTest[num].fillna(0)[:-1]+dfTest[num].fillna(0)[1:]\n",
    "idx=ligne0(t).index\n",
    "#followed=[t.index.get_loc(i) for i in idx]\n",
    "#followed.union\n",
    "base=t.index.get_indexer_for(idx)\n",
    "pd.Index(base).union(pd.Index(base+1))\n",
    "\n",
    "# t.drop(ligne0(t).index,axis=0,inplace=True)\n",
    "#t2=t[num].iloc[:-1]+t[num].iloc[1:]\n",
    "# ligne0(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.Montant.eq(0).mean()/dfC.Mapplique.eq(0).mean()# environ 2x plus de 0 dans Montant que Mapplique\n",
    "\n",
    "test=dfC[dfC.Mapplique.eq(0)]\n",
    "test.Montant.eq(0).mean()#99.5%: presque tous les cas Mapplique nul ont Montant nul\n",
    "excep=test[test.Montant.eq(0)==False]\n",
    "excep#seulement l'exception de la facture 18731.0 pleine de NaN (#668)\n",
    "#D'apres precedant, à l'exception de la facture 18731.0 pleine de NaN (#668),\n",
    "#(Montant==0) == (Mapplique==0)\n",
    "\n",
    "test.sample(30)#Rien de bien interessant\n",
    "#Regardons les cas Montant==0 ^ !(Mapplique==0)\n",
    "test=dfC[dfC.Montant.eq(0)]\n",
    "test=test[test.Mapplique.eq(0).eq(False)]\n",
    "test[:40]#rien d'apparent non plus\n",
    "0\n",
    "#D'apres l'observation globale des donnees, l'explication des 0 se trouve peut etre dans des factures redondantes,\n",
    "#ou dans la proximite des visites entre clients.\n",
    "#Cependant, encore une fois, une partie de l'explication se trouve dans l'analyse des montants negatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montants NEGATIFS\n",
    "Dans le même objectif: expliquer (Montant!=Mapplique)|Arrond \n",
    "- Il y a 24 clients dont le debalancement est equivalent a un arrondi\n",
    "- 355 clients ont un bilan Montant-Mappliquee-Arrond qui ne balance pas, dont 24 qui ont un débalancement équivalent à un Arrond\n",
    "- 375 achats ne balancent pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifier des débalancements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupés par Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "negaClean=[]#index des unites dans le tableau dfC dont les negatfis s'expliquent \n",
    "#(e.g. un montant negatifs 'precede' par le meme montant positif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regarder les montants nuls ou negatifs\n",
    "loupe=dfC[dfC.Montant.lt(1)|dfC.Mapplique.lt(1)|(dfC.Mapplique-dfC.Montant).abs().gt(3)]#taille 1528\n",
    "loupe[:20]#loupe: les montants negatifs, nuls ou lorsque Mapplique!=Montant|Arrond\n",
    "1\n",
    "#La solution n,est pas evidente: peut-être que Facture peut aider a lier ensemble differents index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dencaiss</th>\n",
       "      <th>Dentree</th>\n",
       "      <th>Montant</th>\n",
       "      <th>Arrond</th>\n",
       "      <th>Client</th>\n",
       "      <th>Quart</th>\n",
       "      <th>Facture</th>\n",
       "      <th>Mapplique</th>\n",
       "      <th>IndexRef</th>\n",
       "      <th>Jour</th>\n",
       "      <th>Mois</th>\n",
       "      <th>Annee</th>\n",
       "      <th>Ligne</th>\n",
       "      <th>ValM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2005-06-09</td>\n",
       "      <td>2005-06-09</td>\n",
       "      <td>92216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>16689.0</td>\n",
       "      <td>21936.0</td>\n",
       "      <td>53</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16737.0</td>\n",
       "      <td>70280.0</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2005-06-10</td>\n",
       "      <td>2005-06-10</td>\n",
       "      <td>11097.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>12186.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16773.0</td>\n",
       "      <td>11012.0</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16411.0</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2005-06-20</td>\n",
       "      <td>2005-06-20</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>12637.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>109</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13067.0</td>\n",
       "      <td>8857.0</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13523.0</td>\n",
       "      <td>5181.0</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16411.0</td>\n",
       "      <td>-3013.0</td>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2005-06-28</td>\n",
       "      <td>2005-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>17060.0</td>\n",
       "      <td>7132.0</td>\n",
       "      <td>149</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>-7132.0</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2005-06-07</td>\n",
       "      <td>2005-06-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>17111.0</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>203</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17245.0</td>\n",
       "      <td>-4316.0</td>\n",
       "      <td>204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>507.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>5655.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>240</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17383.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2005-07-22</td>\n",
       "      <td>2005-07-22</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>15923.0</td>\n",
       "      <td>4239.0</td>\n",
       "      <td>280</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16201.0</td>\n",
       "      <td>4762.0</td>\n",
       "      <td>281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17133.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2005-08-15</td>\n",
       "      <td>2005-08-15</td>\n",
       "      <td>14586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>17646.0</td>\n",
       "      <td>8627.0</td>\n",
       "      <td>411</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17764.0</td>\n",
       "      <td>5959.0</td>\n",
       "      <td>412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>2005-08-22</td>\n",
       "      <td>2005-08-22</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>13523.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>481</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13658.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2005-08-23</td>\n",
       "      <td>2005-08-23</td>\n",
       "      <td>34410.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>13445.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>490</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18157.0</td>\n",
       "      <td>33358.0</td>\n",
       "      <td>491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>2005-08-09</td>\n",
       "      <td>2005-08-09</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>18433.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>592</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2005-09-13</td>\n",
       "      <td>2005-09-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>16934.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>616</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18546.0</td>\n",
       "      <td>-1678.0</td>\n",
       "      <td>617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>2005-09-30</td>\n",
       "      <td>2005-09-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>16659.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>703</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2005-07-10</td>\n",
       "      <td>2005-07-10</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>17133.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>745</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>2005-04-11</td>\n",
       "      <td>2005-04-11</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>16659.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>908</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dencaiss    Dentree  Montant  Arrond  Client  Quart  Facture  Mapplique  \\\n",
       "53  2005-06-09 2005-06-09  92216.0       0   412.0  833.0  16689.0    21936.0   \n",
       "54         NaT        NaT      NaN       0     NaN    NaN  16737.0    70280.0   \n",
       "60  2005-06-10 2005-06-10  11097.0       0  1123.0  834.0  12186.0       85.0   \n",
       "61         NaT        NaT      NaN       0     NaN    NaN  16773.0    11012.0   \n",
       "108        NaT        NaT      NaN       0     NaN    NaN  16411.0     3013.0   \n",
       "109 2005-06-20 2005-06-20  16000.0       0    11.0  841.0  12637.0     1962.0   \n",
       "110        NaT        NaT      NaN       0     NaN    NaN  13067.0     8857.0   \n",
       "111        NaT        NaT      NaN       0     NaN    NaN  13523.0     5181.0   \n",
       "119        NaT        NaT      NaN       0     NaN    NaN  16411.0    -3013.0   \n",
       "149 2005-06-28 2005-06-28      0.0       0  1668.0  845.0  17060.0     7132.0   \n",
       "150        NaT        NaT      NaN       0     NaN    NaN  17089.0    -7132.0   \n",
       "203 2005-06-07 2005-06-07      0.0       0  2323.0  850.0  17111.0     4316.0   \n",
       "204        NaT        NaT      NaN       0     NaN    NaN  17245.0    -4316.0   \n",
       "240 2005-07-15 2005-07-15    507.0       0  1406.0  856.0   5655.0       48.0   \n",
       "241        NaT        NaT      NaN       0     NaN    NaN  17383.0      459.0   \n",
       "280 2005-07-22 2005-07-22  12000.0       0    62.0  861.0  15923.0     4239.0   \n",
       "281        NaT        NaT      NaN       0     NaN    NaN  16201.0     4762.0   \n",
       "282        NaT        NaT      NaN       0     NaN    NaN  17133.0     2999.0   \n",
       "411 2005-08-15 2005-08-15  14586.0       0  1490.0  877.0  17646.0     8627.0   \n",
       "412        NaT        NaT      NaN       0     NaN    NaN  17764.0     5959.0   \n",
       "481 2005-08-22 2005-08-22  10000.0       0    11.0  881.0  13523.0     5625.0   \n",
       "482        NaT        NaT      NaN       0     NaN    NaN  13658.0     4375.0   \n",
       "490 2005-08-23 2005-08-23  34410.0       0  2561.0  882.0  13445.0     1052.0   \n",
       "491        NaT        NaT      NaN       0     NaN    NaN  18157.0    33358.0   \n",
       "592 2005-08-09 2005-08-09   6000.0       0  1029.0  893.0  18433.0     6000.0   \n",
       "616 2005-09-13 2005-09-13      0.0       0  1939.0  896.0  16934.0     1678.0   \n",
       "617        NaT        NaT      NaN       0     NaN    NaN  18546.0    -1678.0   \n",
       "703 2005-09-30 2005-09-30     14.0       0    90.0  909.0  16659.0       14.0   \n",
       "745 2005-07-10 2005-07-10   2000.0       0    62.0  914.0  17133.0     2000.0   \n",
       "908 2005-04-11 2005-04-11  12000.0       0    90.0  932.0  16659.0    12000.0   \n",
       "\n",
       "     IndexRef  Jour  Mois   Annee  Ligne ValM  \n",
       "53         53   9.0   6.0  2005.0    NaN  NaN  \n",
       "54         54   NaN   NaN     NaN    NaN  NaN  \n",
       "60         60  10.0   6.0  2005.0    NaN  NaN  \n",
       "61         61   NaN   NaN     NaN    NaN  NaN  \n",
       "108       108   NaN   NaN     NaN    NaN  NaN  \n",
       "109       109  20.0   6.0  2005.0    NaN  NaN  \n",
       "110       110   NaN   NaN     NaN    NaN  NaN  \n",
       "111       111   NaN   NaN     NaN    NaN  NaN  \n",
       "119       119   NaN   NaN     NaN    NaN  NaN  \n",
       "149       149  28.0   6.0  2005.0    NaN  NaN  \n",
       "150       150   NaN   NaN     NaN    NaN  NaN  \n",
       "203       203   7.0   6.0  2005.0    NaN  NaN  \n",
       "204       204   NaN   NaN     NaN    NaN  NaN  \n",
       "240       240  15.0   7.0  2005.0    NaN  NaN  \n",
       "241       241   NaN   NaN     NaN    NaN  NaN  \n",
       "280       280  22.0   7.0  2005.0    NaN  NaN  \n",
       "281       281   NaN   NaN     NaN    NaN  NaN  \n",
       "282       282   NaN   NaN     NaN    NaN  NaN  \n",
       "411       411  15.0   8.0  2005.0    NaN  NaN  \n",
       "412       412   NaN   NaN     NaN    NaN  NaN  \n",
       "481       481  22.0   8.0  2005.0    NaN  NaN  \n",
       "482       482   NaN   NaN     NaN    NaN  NaN  \n",
       "490       490  23.0   8.0  2005.0    NaN  NaN  \n",
       "491       491   NaN   NaN     NaN    NaN  NaN  \n",
       "592       592   9.0   8.0  2005.0    1.0  NaN  \n",
       "616       616  13.0   9.0  2005.0    NaN  NaN  \n",
       "617       617   NaN   NaN     NaN    NaN  NaN  \n",
       "703       703  30.0   9.0  2005.0    1.0  NaN  \n",
       "745       745  10.0   7.0  2005.0    1.0  NaN  \n",
       "908       908  11.0   4.0  2005.0    1.0  NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfC.Facture.shape[0]-len(dfC.Facture.unique())\n",
    "#969 lignes dont la factures est apparues a une date precedante, c'est un nombre proche du nombre de donnees etranges comptees a la fin du chapitre de premieres observations\n",
    "interet=dfC.Facture.value_counts()[dfC.Facture.value_counts().gt(1)]#670 numeros de facture redondants\n",
    "interet.lt(4).mean()#.94: la plupart des factures redondantes sont doublées ou triplées\n",
    "dfF=dfC[dfC.Facture.isin(interet.index)]\n",
    "dfF.set_index('Facture',inplace=True)\n",
    "dfF.sort_index().head(20)\n",
    "#Les factures redondantes correspondent la plupart du temps a des payments decales car\n",
    "#Les dates changent et, sachant que Montant correspond a Mapplique arrondi, \n",
    "#Montant est ce qui est paye par le client.\n",
    "\n",
    "#Essayons de comprendre ce a quoi correspond Mapplique plus precisement\n",
    "dfF0=dfC[num + ['Facture']].groupby('Facture').agg(sum)\n",
    "\n",
    "dfF0[dfF0.Montant.eq(0)]\n",
    "\n",
    "m=(dfF0.Montant.abs()<dfF0.Mapplique.abs())\n",
    "dfOut=dfF.loc[set(dfF0[m].index) & set(dfF.index)]\n",
    "dfOut.head(30)\n",
    "\n",
    "\n",
    "eq0=(dfF0.Montant==dfF0.Mapplique)\n",
    "eq0.mean()#70%\n",
    "eq1=(dfF0.Montant==(dfF0.Mapplique+dfF0.Arrond))\n",
    "eq1.mean()#94%\n",
    "(eq0 & eq1).mean()#70%\n",
    "eq0.sum()-(eq0 & eq1).sum()# 65\n",
    "notF=dfF0[(~eq1 & ~eq0)] # cas ou Facture n'explique pas les differences, 1319 rows\n",
    "dfC[[f in notF.index for f in dfC.Facture]].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facture2=dfF.loc[interet[interet.eq(2)].index]\n",
    "facture2.head(30)#On a quand meme quelques cas interessants de negatifs a eliminer\n",
    "test=facture2.groupby(by='Facture').sum()\n",
    "x=test[test.Mapplique.eq(0)]\n",
    "if x.Montant.eq(0).shape[0]==x.shape[0]:\n",
    "    Itest=test[test.Mapplique.eq(0) & test.Montant.eq(0)].index# length=188\n",
    "solution2=dfF.loc[Itest]#Ca semble une reussite\n",
    "solution2.Mapplique.lt(0).sum()#188\n",
    "dfF.Mapplique.lt(0).sum()#358: On a vrm juste enleve la moitie des negatifs.\n",
    "\n",
    "facture3=dfF.loc[interet[interet.eq(3)].index]\n",
    "facture3.head(30)#On a quand meme quelques cas interessants de negatifs a eliminer\n",
    "test=facture3.groupby(by='Facture').sum()\n",
    "x=test[test.Mapplique.eq(0)]\n",
    "x#Seulementla Facture 18465\n",
    "\n",
    "dfIt=facture3.reset_index()\n",
    "sol=[]\n",
    "for i in dfIt.index[:-1]:\n",
    "    if (dfIt.loc[i+1].Montant+dfIt.loc[i].Montant)==0: sol.append(dfIt.Facture.loc[[i,i+1]])\n",
    "#dfIt.loc[[i for sub in sol for i in sub]].head(20)#pas de mauvaise surprise\n",
    "sol=[x for sub in sol for x in sub]#Flatten\n",
    "sol2=[]\n",
    "[sol2.append(x) for x in sol if x not in sol2]\n",
    "sol=sol2\n",
    "len(sol)#109\n",
    "\n",
    "#Itest=test[test.Mapplique.eq(0) & test.Montant.eq(0)].index# length=188\n",
    "#solution3=dfF.loc[Itest]#Ca semble une reussite\n",
    "#solution3.Mapplique.lt(0).sum()#188\n",
    "# dfF.Mapplique.lt(0).sum()#358: On a vrm juste enleve la moitie des negatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procede un peu au tir au pigeon; il est temps d'élaborer un plan qui puisse être automatisé pour répondre à l'objectif du projet.\n",
    "1. Cleaning:\n",
    "    1. Arrond==Nan <- 0\n",
    "2. On traite les négatifs: \n",
    "    - Facture.isna(): \n",
    "    - Sélectionner des paramètres pour former les groupes et les nettoyer\n",
    "    - Former les groupes et repérer des combinaisons de montants pour un meme client dont la somme est à peu près nulle\n",
    "\n",
    "Les donnees negatives charrient de l'information: elles pourraient s'avérer névralgiques au modèle de détection de fraudes. Il faut donc un algorythme qui permette en général et clairement d'isoler les nombres négatifs et les valeurs positives associées. Formellement: \n",
    "+ Nous faisons l'hypothèse que lorsque la somme de une ou plusieurs valeurs positives ont une somme négative équivalente sous le même nom, ces données ont une interprétation particulière (e.g. un remboursement) et doivent donc être considérées comme facteur dans le modèle au travers de certaines statistiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools#pour generer les combinaisons d'ensembles\n",
    "\n",
    "def pairing(groups,**conditions):\n",
    "    #pair les elements des groupes de groups selon des conditions \n",
    "    #On assume que groups est de profondeur 2 \n",
    "    \n",
    "    Imatchs=[[],[]]#Contient l'indice des paires, sert notamment a valider l'algo\n",
    "    \n",
    "    #if not conditions=='negatif': print( 'ben ça alors') ?Prq ne fonctionne pas?\n",
    "    setNega=groups[0]\n",
    "    setPos=groups[1]\n",
    "\n",
    "    #On supprime en cours les elements pairez, afin d'alleger l'algo\n",
    "    baseN=list(setNega)\n",
    "    baseP=list(setPos)\n",
    "    tN=0#le nombre de negatifs pris ensembles\n",
    "    while (tN<=len(baseN)):#On arrete si toutes les combinaisons des positifs restants ont ete verifiees\n",
    "        tN=tN+1\n",
    "        for sN in itertools.combinations(baseN,tN):\n",
    "            tP=0#Pour chaque combinaison de negatifs sN, on cherche une combinaison de positifs sP de taille tP\n",
    "            while (tP<=len(baseP)):\n",
    "                tP=tP+1\n",
    "                for sP in itertools.combinations(baseP,tP):\n",
    "                    if sum(sN)+sum(sP)==0:\n",
    "                        #print(sN+sP)\n",
    "                        #print(baseP)\n",
    "                        for s in sP: \n",
    "                           # print(setPos.index(s))\n",
    "                            Imatchs[0].append(setPos.eq(s).index[0])\n",
    "                            baseP.remove(s)\n",
    "                        for s in sN: \n",
    "                            Imatchs[1].append(setNega.eq(s).index[0])\n",
    "                            baseN.remove(s)\n",
    "                        break\n",
    "                break\n",
    "            #On passe au prochain sN de taille tN, en commençant avec tP=0\n",
    "                         \n",
    "    return Imatchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set1=(-3,-5,-1)\n",
    "# set2=(1,2,3,4)\n",
    "# i=pairing([set1,set2])\n",
    "# #[set1,set2][i]\n",
    "# t=[set1,set2]\n",
    "# [[set1[e] for e in i[0]],[set2[e] for e in i[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD=dfC.groupby('Client').apply(lambda x: np.sum(x['Montant']-x['Mapplique']-x['Arrond']))\n",
    "unbalanced=dfD[dfD.abs().gt(1)]#len=355\n",
    "unbalanced.abs().gt(2).sum()#331: 24 clients dont le debalencement est equivalent a un arrondi\n",
    "loupe=dfC[dfC.Client.isin(unbalanced.index)].set_index('Client').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loupe=dfC.groupby('Client').filter(lambda x: x.Montant.sum()!=x.Montant.abs().sum())\n",
    "#loupe=loupe.set_index('Client').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairtest (groups):\n",
    "    setNega=groups[0]\n",
    "    setPos=groups[1]\n",
    "\n",
    "    #On supprime en cours les elements paires, afin d'alleger l'algo\n",
    "    baseN=list(setNega)\n",
    "    baseP=list(setPos)\n",
    "    return (baseN,baseP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=loupe.groupby('Client').apply(lambda x: pairing([x.query('Montant<0').Montant,x.query('Montant>0').Montant]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenList (sol, sub):\n",
    "    #Algo recursif pour flatten une liste... j,avoue ne pas avoir beaucoup d'idees sans utiliser Error handling\n",
    "    if isinstance(sub,list):\n",
    "        while not len(sub)==0:\n",
    "            flattenList(sol, sub[0])\n",
    "            sub.pop(0)\n",
    "    else:\n",
    "        sol.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loupe[:20]\n",
    "dfC[dfC.Montant.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=loupe.groupby('Client').apply(lambda x: pairing([x.query('Montant<0').Montant,x.query('Montant>0').Montant]))\n",
    "loupe.loc[sol].set_index('Client').sort_index()[40:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=loupe.groupby('Client').apply(lambda x: pairing([x.query('Montant<0').Montant,x.query('Montant>0').Montant]))\n",
    "sol=[]\n",
    "#l=test.values.copy(): ?prq n,empeche pas test de disparaitre dans flattenlist?\n",
    "flattenList(sol, list(test.values))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Des cas Facture.isna(): 42 dans cet exemple, on trouve ceux qui balancent.\n",
    "dfT=dfC[dfC.Facture.isna()]\n",
    "x=dfT  .groupby('Client').filter(lambda x: (np.sum(x['Montant'])==0 and np.sum(x['Mapplique'])==0))\n",
    "x.shape[0]#39 lignes \n",
    "m=dfT.drop(x.index)#les 3 restants\n",
    "probList.append(m)\n",
    "#dfC[dfC.Facture.isna()][m]\n",
    "m=dfC.Facture.value_counts().gt(1)\n",
    "fs=m[m].index\n",
    "dfC.set_index('Facture').sort_index().loc[fs].head(60)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.pivot_table(index='Facture').loc[dfC.Facture.value_counts().gt(1).index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation\n",
    "\n",
    "+ On peut produire des statistiques, mais probablement qu'on doit se concentrer sur une ou deux années consécutives afin d'éviter l'effet de l'inflation/changement dans les prix. \n",
    "+ Les séries chronologiques pourraient être contre-indiquée  Il n'y a pas de lien direct entre les valeurs consécutives, bien qu'on se doute le temps soit une variable a effet significatif\n",
    "\n",
    "Je propose pour commencer un modèle multivarié prenant en compte le mois, l'année, le jour de la semaine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan d'analyse:\n",
    "\n",
    "Information dans \n",
    "+ le jour de la semaine: influence des quarts de travail et du type de service offert \n",
    "+ cycle annuel: ajustement annuel des prix\n",
    "\n",
    "Reste maintenant à évaluer la pertinance de chaque cas. Pour cela, il faut qualifier l'état normal des choses. La statistique offre de belles hypothèses pour celà et une communauté de référence. Une hypothèse serait par exemple l'indépendance des ventes selon les jours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('qtagg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see above 95% correlation with Montant-Mapplique and Facture-Quart :\n",
    "#  we shouldn't put any of these pairs together as explanatory variables in a linear model\n",
    "dfC.corr()\n",
    "# Their are no good correlations between Montant and other varibles then Mapplique\n",
    "0.1/np.sqrt 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC['month']=dfC.Dencaiss.dt.month\n",
    "dfC['weekday']=dfC.Dencaiss.dt.weekday\n",
    "dfC['year']=dfC.Dencaiss.dt.year\n",
    "D=dfC[dfC.columns.drop(['Arrond','Quart','Facture','Montant','Client','Dencaiss','Dentree'])]\n",
    "D=D.dropna()\n",
    "\n",
    "\n",
    "yString='Mapplique'\n",
    "X=D[D.columns.drop(yString)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, D[yString], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "model = ols.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction =  model.predict(X_test)\n",
    "(y_test-y_prediction).abs().mean()/(y_test.mean()-y_test).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfC.Montant est probablement le montant paye par le client: on voit Mapplique+Arrondi donne Montant Mod .05 ==0\n",
    "type(dfC.Dencaiss[0])\n",
    "dtS=dfC.Dencaiss\n",
    "dfD=dfC.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfM=dfC.groupby('Dencaiss').agg(sum)\n",
    "dfM['dayofweek']=[x.dayofweek for x in dfM.index]\n",
    "dfM.groupby('dayofweek').describe()['Montant']\n",
    "dfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfM=dfC.groupby('Dencaiss').agg(sum)\n",
    "dfM['dayofweek']=[x.dayofweek for x in dfM.index]\n",
    "\n",
    "\n",
    "fig,ax= plt.subplots(5,1,sharex=True)\n",
    "n_b=150\n",
    "N=n_b*10\n",
    "ax[0].hist(dfM.Montant.values[:N],bins=n_b)[1]\n",
    "ax[1].hist(dfM.query('dayofweek==1').Montant[10:N],bins=n_b)[1]\n",
    "ax[2].hist(dfM.query('dayofweek==2').Montant[10:N],bins=n_b)[1]\n",
    "ax[3].hist(dfM.query('dayofweek==3').Montant[10:N],bins=n_b)[1]\n",
    "ax[4].hist(dfM.query('dayofweek==4').Montant[10:N],bins=n_b)[1]\n",
    "#ax.x\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# ax[0,0].plot(dfM.index[:N],dfM.Montant[:N])\n",
    "# ax[0,1].plot(dfM.query('dayofweek==1').index[10:N],dfM.query('dayofweek==1').Montant[10:N],'.')\n",
    "# ax[1,0].plot(dfM.query('dayofweek==2').index[10:N],dfM.query('dayofweek==2').Montant[10:N])\n",
    "# ax[1,1].plot(dfM.query('dayofweek==3').index[10:N],dfM.query('dayofweek==3').Montant[10:N])\n",
    "# # for a in ax:\n",
    "#     a.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "#test=dfM.groupby([[x.month for x in dfM.index]]).mean()#.tail(40)\n",
    "#test\n",
    "#dfM.query('dayofweek==5')\n",
    "#dfM.query('dayofweek==5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(test.Montant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non CLASSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les redondances dans les numeros de facture proviennent de payements par bouts\n",
    "#Les factures peuvent-elles servire comme index?\n",
    "\n",
    "len(df.Facture.unique())/len(df.Facture)#96%\n",
    "#Nous pensions à tort que les factures étaient uniques; tachons de trouver les redondances (4%)\n",
    "s=df.Facture.value_counts()\n",
    "s.gt(1).sum()#670\n",
    "s.gt(2).sum()#500 environ=2\n",
    "s.gt(3).sum()#140 ==3\n",
    "s.eq(4).sum()#21\n",
    "s.eq(5).sum()#8\n",
    "s.gt(5).sum()#8\n",
    "#Concentrons nous alors sur les 8 plus grandes factures\n",
    "m=df.Facture.eq(s.index[0])\n",
    "df[m].shape[0]#pas d'erreur\n",
    "df[m]#On remarque que c'etait toujours la meme cliente Noelle Hannibal, la meme annee, Mapplique sont des montants ronds\n",
    "df[df.Facture.eq(s.index[1])]#Maureen Cannon, pas les memes dates, Mapplique=(300,50,100,...)\n",
    "x=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapplique NaN\n",
    "dfnw=df.Mapplique.dropna()\n",
    "dfnw=pd.to_numeric(dfnw, errors='coerce')\n",
    "l1=len(dfnw)\n",
    "l1-len(dfnw.dropna())#10 erreurs dans dfnw:c negligeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrondis\n",
    "df.Arrond.isna().mean()#75%\n",
    "df.Arrond.unique()\n",
    "df.Arrond.value_counts()#.01:1750, .02:1658, -.02:1502, -.01:1486\n",
    "df.Arrond.dropna().mean()#.09%\n",
    "#Nous ne pensons pas qu'une augmentation de valeur en moyenne de .09% dans le cas d'arondis soit significatif.\n",
    "#D'experience, un test non-paramétrique (H0:somme=0, H1:somme>0) ne sera pas positif et je ne vois pas d'hypotese a faire sur la distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.isna().sum(axis=0)\n",
    "#On a 20x plus de nan dans Montant que dans Mapplique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=df.Montant[df.Montant.isna()].index\n",
    "test=df.loc[i]\n",
    "test.isna().apply(np.mean,axis=0)\n",
    "#On voit que tous les attribus sont pleins de NaN sauf Facture et Mapplique\n",
    "test.index[0:10]# Int64Index([54, 61, 107, 108, 110, 111, 118, 119, 150, 204], dtype='int64')\n",
    "df.loc[52:63]#On voit que NaN 54 et 61 correspondent a des factures incompletes\n",
    "#Une facon de corriger serait d'ajouter les Mapplique de 'test' au Mapllique de l'index precedant\n",
    "vAdd=df.Mapplique[test.index].values+df.Mapplique[test.index-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nous reperons certaines valeurs non-numeriques: Factures 85902,86157 et 10628: elles  \n",
    "\n",
    "a=df.Mapplique[test.index].values\n",
    "b=df.Mapplique[test.index-1].values\n",
    "iAnormal=np.isnan(pd.to_numeric(a,errors='coerce'))\n",
    "iAnormal=df.Mapplique[test.index][iAnormal].index\n",
    "df.loc[iDf[0]-5:iDf[0]+5]\n",
    "df.loc[17495:17497].Facture.values\n",
    "#les factures 85901,85902 et 86157 ont comme client l'entreprise \n",
    "#elles sont balencees (presence d'un -x==y+z)\n",
    "#On en deduit que le '2Ê'present dans Factures:85902 et 86157 sont des erreurs, a eliminer\n",
    "df.loc[iDf[-1]-3:iDf[-1]+3]\n",
    "df[df.Mapplique==df.Mapplique[21461]-159.52]#Nous ne trouvons par le sens de la donnee\n",
    "df.loc[iDf[-1]]#21462:Mapplique=1Ê159,52$, Facture=10628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[iDf[0]-5:iDf[0]+5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################\n",
    "\n",
    "# Analyse\n",
    "\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour simplifier\n",
    "num=['Montant','Arrond','Mapplique']\n",
    "dfT=dfC[num]\n",
    "dfT=dfT.dropna()\n",
    "\n",
    "#corrigeons les nombres significatifs et rappelons nous que les tests variable==constante sont dangereux avec des données brutes.\n",
    "#Je signalerai la delicatesse du projet. Par exemple, j'ai eu\n",
    "# subs.Montant[0]-8; #output: 0 # 8 etant la valeur apparente de de Montant\n",
    "#      mais subs.Montant[0]%.01 # output: .009999999...., 1- 166e-19\n",
    "# on ne peut donc pas effectuer dirrectement des operations arithmetiques pour corriger les donnees\n",
    "# le plus simple serait de trouver une fct round\n",
    "\n",
    "\n",
    "\n",
    "dfT.Montant.mul(100).mod(1).ne(0).sum()#7316 : cas ou il y a trop de chiffres significatifs\n",
    "dfT.Montant.mul(100).round(0).mod(1).ne(0).sum()#0\n",
    "dfC.Montant.mul(100).round(0).mod(1).ne(0).sum()# out: 890; 890==Nan\n",
    "\n",
    "#On detient la solution pour corriger les chiffres significatifs\n",
    "correct=dfC[num].mul(100).round(0).div(100)# out: 890; 890==Nan\n",
    "dfC[num]=dfC[num].where(dfC[num].isna(), correct)\n",
    "dfC[num].mul(100).mod(1).ne(0).sum()#~3800 : montant, 2800 : Mapplique\n",
    "(.1%1)==.1#True\n",
    "(1.1%1)==.1 #False\n",
    "(1.25%1)==.25# True\n",
    "#l'operateur % provoque les erreurs d'estimation lors de conversion en base 2 de fractions en base 10, dans certains cas.\n",
    "correct.mul(100).round(0).mod(1).ne(0).sum()#890 : seulement les NaN\n",
    "# correct.mul(100).round(0).div(100).mul(100).mod(1).ne(0).sum()# 3800 : 1/100 n'a pas de representation exacte en base 2\n",
    "x=10\n",
    "i=0\n",
    "while(i<10000):\n",
    "    if (i%2==0):\n",
    "        x=x/100\n",
    "    else:\n",
    "        x=x*100\n",
    "    i=i+1\n",
    "(x/100)%1==.1# True : il n'y a pas d'erreur de propagation en "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aventure due au comportement inattendu de l'operateur % dans les cas a%m, m<1\n",
    "\n",
    "\n",
    "\n",
    "#faisons les calculs en bases 2: 10^-2 = 2^p, p=\n",
    "p=np.floor(-2/np.log10(2))#-7 : prec\n",
    "p=2# p est la position ou l'on souhaite arrondir, soit 1e(-p)\n",
    "dfR=dfT.round(p)\n",
    "dfR.mod(10^-p).eq(0).mean()#<.02: la fct round ne fct pas\n",
    "dfR.mod(10^-(p+2)).eq(0).mean()#<.07: la fct round ne fct pas\n",
    "del(dfR)\n",
    "\n",
    "# Corrigeons les chiffres significatifs en prenant garde de bien arrondir\n",
    "subs=dfT[['Montant','Mapplique']].mod(.01)# on voit les erreurs de precision dans chiffres significatifs\n",
    "\n",
    "# soyon certains du comportement des operateurs % et de la fct DataFrame.mod()\n",
    "subs.eq(.01).sum()# 0\n",
    "nonSign=subs[subs.ge(.005)]#chiffres nons-significatifs a arrondir vers le haut\n",
    "dfCorr=dfT[['Montant','Mapplique']].loc[nonSign.index]-nonSign\n",
    "obs=dfCorr.merge(dfT[['Montant','Mapplique']],left_index=True,right_index=True)\n",
    "obs=obs.dropna()\n",
    "obs.Montant_x-obs.Montant_y# donne confiance dans le bon fonctionnement de mod, fct aussi pour operateur %\n",
    "\n",
    "#arrondissons manuellement Montant et Mapplique\n",
    "\n",
    "dfT=dfC.dropna()\n",
    "dfT=dfT[['Montant','Mapplique','Arrond']]\n",
    "residu=dfT%.01\n",
    "dfT=dfT.where(residu.lt(.005),other=dfT.add(.01))\n",
    "dfT=dfT-residu\n",
    "test=dfT%.01\n",
    "(test==residu).mean()# les corrections sont innefficaces, bien qu'elles aient un effet\n",
    "test.eq(0).sum()-residu.eq(0).sum()# On n'a eu aucun effet sur le probleme..., surement une question de calculs en virgules flottantes\n",
    "#Pourtant d'apres mes connaissances sur le sujet, il n'y a pas de probleme a calculer x - x%fl.\n",
    "#les problemes surviennent dans une différence lorsqu'on additionne ou soustrait des nombres dont les chiffres significatifs sont plus nombreux\n",
    "#que l'espace accorde en machine pour les chiffres significatifs.\n",
    "\n",
    "e=residu[residu.gt(0)].min()# on devine que epsilon est de l'ordre de 1e-24\n",
    "i=residu[residu.eq(e)].index\n",
    "fl=dfT.loc[i].iloc[2].Montant\n",
    "\n",
    "m=1e-2# On teste notre systeme de correction A qui est de soustraire les quantites inutiles, afin d'arrondir manuellement\n",
    "r=fl%m\n",
    "fl==(fl-r)#True\n",
    "fl2=fl/2\n",
    "fl2==(fl2-r)#True\n",
    "fl2=fl/4\n",
    "fl2==(fl2-r)#False\n",
    "\n",
    "#nous utilisons les principes de calculs en virgules flottantes pour supprimer un certain nombre de chiffres significatifs, en espérant pouvoir\n",
    "#ensuite arrondir avec les methodes precedemment tentees : pd.round and x-x%.01\n",
    "\n",
    "#find epsilon\n",
    "eps=1\n",
    "while(1!=(1+eps)):\n",
    "    eps=eps/2\n",
    "eps=eps*2# 2,22e-16\n",
    "np.log2(eps)#-52\n",
    "\n",
    "#n: the number of digits we want to keep in base 2\n",
    "#n=dfT[['Montant']].applymap(lambda x: np.floor(np.log2(x*100))+1).max().values[0]#17\n",
    "n=dfT[['Montant']].where((dfT.Montant.lt(.009)) & (dfT.Montant.ne(0)), lambda x: np.floor(np.log2(x*100*x/abs(x)) )).max().values[0]#17\n",
    "\n",
    "(2**n)/100 #1310,72\n",
    "n=int(n+3)# On ajoute 3 digits pour plus d'assurance\n",
    "n#20\n",
    "\n",
    "def signifCut(x, n, eps):\n",
    "    #keeps only the n first digits of x, using a trick with machine precision eps\n",
    "    eps2=eps*(2**(n-1))\n",
    "    sol=((x+x*eps2)-x)/eps2\n",
    "    return sol\n",
    "test=dfT.Montant.apply(lambda x: signifCut(x, n=n, eps=eps))#n=np.log2(x*100)+1\n",
    "test2=test.dropna().mod(.01).value_counts().sort_index()\n",
    "test2[test2.index<.009].sum()#10 646 avec n=n\n",
    "#avec n=55 : 14 375\n",
    "#avec n=1 : 957 \n",
    "# n=20 ~ 10 000\n",
    "# n=17 ~ n=20\n",
    "# la methode fonctionne comme prevu, mais ne donne pas le resultat espere, bien qu'elle apporte un 33% de corrections\n",
    "\n",
    "#Essayons en utilisant la fct int()\n",
    "test=test.apply(lambda x: int(x*100)/100)\n",
    "test2=test.dropna().mod(.01).value_counts().sort_index()\n",
    "test2[test2.index<.009].sum()#8977\n",
    "# En partant de dfT.Montant: 8946\n",
    "int(n)%.01# !=0, int ou % cache des surprises\n",
    "#l'efficacite de la methode int est tres tres proches de celle s'appuyant sur les principes de calcul en virgules flottantes\n",
    "\n",
    "compar=dfT.merge(test, left_index=True, right_index=True, how='inner')\n",
    "compar[(compar.Montant_x!=compar.Montant_y)]\n",
    "#On voit qu'on a oublier d'arrondir avec la methode int.\n",
    "test=dfT.Montant.apply(lambda x: signifCut(x, n=n, eps=eps))#n=np.log2(x*100)+1\n",
    "compar=dfT.merge(test, left_index=True, right_index=True, how='inner')\n",
    "compar[(compar.Montant_x!=compar.Montant_y)]\n",
    "\n",
    "int(2.04895782754368057249605786)%.01#.00999...959\n",
    "1%.01\n",
    "100%1#0\n",
    "\n",
    "#################################\n",
    "#bref il ne faut pas utiliser de modulo<1\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maintenant que l'on sait ne pas utiliser %x, x<1; refaisons l'analyse et la correction des chiffres significatifs\n",
    "test=(dfC.Montant*100)%1\n",
    "test.gt(0).mean()#11.4%\n",
    "test=(dfC.Montant*1000)%10\n",
    "test.gt(0).mean()#1.2%\n",
    "((1/10)*10)%1# 0\n",
    "#ce deuxieme test x*1000%10 devrait obtenir le même resultat que x*100%1, sauf que \n",
    "#les methodes de calculs numeriques ont le pouvoir mystique de reajuster les imprecisions dans la representation de certains \n",
    "#nombres lorsque les calculs sont faits. Peut-être simplement par les principes evitant la propagation des erreurs d'arrondis\n",
    "\n",
    "for i in range(7):\n",
    "    f=10**i\n",
    "    #f=2**i\n",
    "    test=(dfC.Montant*(10000*f))%f\n",
    "    #print(f)\n",
    "    #print(test.gt(0).mean())\n",
    "#les erreurs oscillent; la meilleure est à f==10: 1.2%, la pire à f==1000000 : 13.7%\n",
    "#Je ne sais pas pourquoi;  car pr un certain x,i : si x*(10**i) est sans erreur de representation, \n",
    "#alors x*(10**i)*(10**j)== x*(10**(i+j)), pour j>0 et j naturel\n",
    "\n",
    "#avec #f=2**i, on a la même erreur que f=1 pour tout i, comme attendu\n",
    "\n",
    "#bref coupons courts les jeux de representation en machine à l'aide des outils de programmation\n",
    "#sachant que x%y a un comportement certain pour y>=1\n",
    "test=((dfC.Montant*100)%1)\n",
    "(test.gt(.1)&test.lt(.9)).sum()#0\n",
    "#on peut donc arrondir sans remord sur la precision: on va conciderer les chiffres <.01 comme des imprecisions machine ou \n",
    "#des attributs des donnees sources que nous pouvons ignorer\n",
    "\n",
    "def arrond(x,p):\n",
    "    #arrondi x a p apres la virgule\n",
    "    if np.isnan(x):\n",
    "        return x\n",
    "    s=1\n",
    "    if x<0:\n",
    "        s=-1\n",
    "    x=np.abs(x)\n",
    "    \n",
    "    x=x*(10**p)\n",
    "    r=x%1\n",
    "    x=int(x)#x>=int(x) pour tout x>0\n",
    "    if r>=.5:\n",
    "        x=x+1\n",
    "    x=x*(10**-p)\n",
    "    return(x*s)\n",
    "#arrond(.55,1)# .60000....001\n",
    "#arrond(-105.49999,0)#-105\n",
    "dfC[num]=dfC[num].applymap(lambda x: arrond(x,2))\n",
    "\n",
    "m=dfRef[num]!=dfC[num]\n",
    "m=m.apply(lambda x: x[0]|x[1]|x[2],axis=1)\n",
    "test=dfC[num].loc[m[m].index].merge(dfRef[num].loc[m[m].index],left_index=True,right_index=True)\n",
    "test[test.columns[[2,5]]].dropna().apply(lambda x:x[0]==x[1],axis=1).mean()-1#0 for columns 0 and 3, 1 and 4, 2 and 5\n",
    "#there has been no changes on the expression of the information after rounding: we can assume the representation \n",
    "#at data importation was correct. Rounding up was useless.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
